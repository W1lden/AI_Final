{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список ключевых слов\n",
    "keywords = [\n",
    "    \"Коррупция\", \"Взятки\", \"Подкуп\", \"Злоупотребление полномочиями\", \"Непотизм\",\n",
    "    \"Конфликт интересов\", \"Теневая экономика\", \"Финансовые махинации\", \"Противодействие коррупции\", \n",
    "    \"Транспарентность\", \"Подотчетность\", \"Мониторинг\", \"Антикоррупционная политика\",\n",
    "    \"Прозрачность финансирования\", \"Теневые сделки\", \"Откаты\", \"Хищение\",\n",
    "    \"Лоббизм\", \"Незаконное обогащение\", \"Контроль расходов\", \"Проверки деятельности\",\n",
    "    \"Аудит\", \"Социальный контроль\", \"Общественные расследования\", \"Антикор\",\n",
    "    \"Мониторинг закупок\", \"Эффективность управления\", \"Ответственность руководства\", \"Правозащитные организации\",\n",
    "    \"Уголовное преследование\", \"Электронное правительство\", \"Похищение\", \"Отмывание\", \"Задержание\", \"Рейдерство\",\n",
    "    \"Превышение власти\"\n",
    "]\n",
    "\n",
    "keywords_english = [\n",
    "    \"Corruption\", \"Bribes\", \"Kickbacks\", \"Abuse of authority\", \"Nepotism\",\n",
    "    \"Conflict of interest\", \"Shadow economy\", \"Financial machinations\", \"Anti-corruption efforts\", \n",
    "    \"Transparency\", \"Accountability\", \"Monitoring\", \"Anti-corruption policy\",\n",
    "    \"Financial transparency\", \"Shadow deals\", \"Embezzlement\", \"Theft\",\n",
    "    \"Lobbying\", \"Illicit enrichment\", \"Expenditure control\", \"Audits\",\n",
    "    \"Audit\", \"Social control\", \"Public investigations\", \"Anti-corruption\",\n",
    "    \"Procurement monitoring\", \"Management efficiency\", \"Responsibility of leadership\", \n",
    "    \"Human rights organizations\", \"Criminal prosecution\", \"E-Government\", \n",
    "    \"Abduction\", \"Money laundering\", \"Arrest\", \"Raiding\", \"Abuse of power\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m keywords_english)\n\u001b[1;32m      2\u001b[0m \u001b[39m# Инициализация pymorphy2\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m morph \u001b[39m=\u001b[39m pymorphy2\u001b[39m.\u001b[39;49mMorphAnalyzer()\n\u001b[1;32m      5\u001b[0m \u001b[39m# Функция для генерации всех возможных форм слова\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_forms\u001b[39m(word):\n",
      "File \u001b[0;32m~/Documents/KBTU/3 semestr/AI/Final/myenv/lib/python3.11/site-packages/pymorphy2/analyzer.py:224\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[0;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_type_orig \u001b[39m=\u001b[39m result_type\n\u001b[1;32m    223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_char_substitutes(char_substitutes)\n\u001b[0;32m--> 224\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_units(units)\n",
      "File \u001b[0;32m~/Documents/KBTU/3 semestr/AI/Final/myenv/lib/python3.11/site-packages/pymorphy2/analyzer.py:235\u001b[0m, in \u001b[0;36mMorphAnalyzer._init_units\u001b[0;34m(self, units_unbound)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m item[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 235\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_unit(unit), \u001b[39mFalse\u001b[39;00m))\n\u001b[1;32m    236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_unit(item[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), \u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/KBTU/3 semestr/AI/Final/myenv/lib/python3.11/site-packages/pymorphy2/analyzer.py:246\u001b[0m, in \u001b[0;36mMorphAnalyzer._bound_unit\u001b[0;34m(self, unit)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_bound_unit\u001b[39m(\u001b[39mself\u001b[39m, unit):\n\u001b[0;32m--> 246\u001b[0m     unit \u001b[39m=\u001b[39m unit\u001b[39m.\u001b[39;49mclone()\n\u001b[1;32m    247\u001b[0m     unit\u001b[39m.\u001b[39minit(\u001b[39mself\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[39mreturn\u001b[39;00m unit\n",
      "File \u001b[0;32m~/Documents/KBTU/3 semestr/AI/Final/myenv/lib/python3.11/site-packages/pymorphy2/units/base.py:35\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit.clone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_params())\n",
      "File \u001b[0;32m~/Documents/KBTU/3 semestr/AI/Final/myenv/lib/python3.11/site-packages/pymorphy2/units/base.py:76\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     74\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[0;32m---> 76\u001b[0m         (key, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, key, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_param_names()\n\u001b[1;32m     77\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/KBTU/3 semestr/AI/Final/myenv/lib/python3.11/site-packages/pymorphy2/units/base.py:70\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n\u001b[0;32m---> 70\u001b[0m args, varargs, kw, default \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mgetargspec(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msorted\u001b[39m(args[\u001b[39m1\u001b[39m:])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame(columns=[\"Date\"] + keywords_english)\n",
    "# Инициализация pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# Функция для генерации всех возможных форм слова\n",
    "def generate_forms(word):\n",
    "    parsed = morph.parse(word)[0]\n",
    "    return {form.word for form in parsed.lexeme}\n",
    "\n",
    "# Генерируем все формы для ключевых слов\n",
    "keyword_forms = {}\n",
    "for keyword in keywords:\n",
    "    keyword_forms[keyword.lower()] = generate_forms(keyword.lower())\n",
    "\n",
    "# Объединяем все формы в один набор для поиска\n",
    "all_keyword_forms = set()\n",
    "for forms in keyword_forms.values():\n",
    "    all_keyword_forms.update(forms)\n",
    "\n",
    "# Лемматизация текста и поиск ключевых слов\n",
    "def find_keywords_in_text(text):\n",
    "    tokens = text.lower().split()  # Разбиваем текст на слова\n",
    "    matched_keywords = [token for token in tokens if token in all_keyword_forms]\n",
    "    return Counter(matched_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tengrinews.kz/tag/%D0%BA%D0%BE%D1%80%D1%80%D1%83%D0%BF%D1%86%D0%B8%D1%8F/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list = soup.find_all('div', {'class': 'content_main_item'})\n",
    "stop_point = 2  # Лимит ссылок для тестирования\n",
    "news_links = []\n",
    "\n",
    "for news_item in news_list:\n",
    "    first_link = news_item.find('a', href=True)  # Берём только первую ссылку внутри каждого блока\n",
    "    if first_link:  # Фильтруем по началу ссылки\n",
    "        news_links.append(first_link['href'])\n",
    "    # if len(news_links) >= stop_point:  # Ограничиваем количество ссылок\n",
    "    #     break\n",
    "        \n",
    "# Убираем дублирующиеся ссылки\n",
    "news_links = list(set(news_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_point = 2  # Лимит ссылок для тестирования\n",
    "\n",
    "# Парсим новости\n",
    "for link in news_links:\n",
    "    # Проверяем, является ли ссылка абсолютной\n",
    "    if link.startswith('https'):\n",
    "        full_url = link  # Абсолютную ссылку оставляем без изменений\n",
    "    else:\n",
    "        full_url = f\"https://tengrinews.kz{link}\"  # Добавляем домен только к относительным ссылкам\n",
    "    \n",
    "    # Получаем текст новости\n",
    "    news_response = requests.get(full_url, headers=headers)\n",
    "    news_soup = BeautifulSoup(news_response.text, \"html.parser\")\n",
    "    \n",
    "    # Извлекаем дату публикации\n",
    "    date_element = news_soup.find('div', {'class': 'date-time'})\n",
    "    if date_element:\n",
    "        date_full = date_element.get_text(strip=True)\n",
    "        date = date_full.split('|')[0].strip()  # Берём только день, месяц и год\n",
    "\n",
    "    # Извлекаем текст новости\n",
    "    article_body = news_soup.find('div', {'class': 'content_main_text'})\n",
    "    if article_body:\n",
    "        text = article_body.get_text(strip=True)\n",
    "        keyword_counts = find_keywords_in_text(text)\n",
    "\n",
    "        # Создаём словарь для строки DataFrame\n",
    "        row = {key: 0 for key in keywords_english}\n",
    "        row[\"Date\"] = date\n",
    "\n",
    "\n",
    "        # Заполняем количество упоминаний ключевых слов\n",
    "        for keyword_rus, count in keyword_counts.items():\n",
    "            keyword_eng = keywords_english[keywords.index(keyword_rus.capitalize())]\n",
    "            row[keyword_eng] = count\n",
    "\n",
    "        # Добавляем строку в DataFrame\n",
    "        dataset = pd.concat([dataset, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "        # # Выводим результат\n",
    "        # print(f\"URL: {full_url}\")\n",
    "        # print(\"Ключевые слова и количество упоминаний:\")\n",
    "        # for keyword, count in keyword_counts.items():\n",
    "        #     if count > 0:\n",
    "        #         print(f\"{keyword}: {count}\")\n",
    "        # print(\"-\" * 40)\n",
    "\n",
    "        print(article_body.text)\n",
    "    # if len(news_links) >= stop_point:  # Ограничиваем количество ссылок\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем DataFrame в файл\n",
    "dataset.to_csv(\"news_dataset.csv\", index=False)\n",
    "\n",
    "# Просмотр результата\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # news_response = requests.get(\"https://tengrinews.kz/sng/spetsslujbyi-zaderjali-eks-glavu-mchs-kyirgyizstana-556711/\", headers=headers)\n",
    "# # news_soup = BeautifulSoup(news_response.text, \"html.parser\")\n",
    "\n",
    "# # article_body = news_soup.find('div', {'class': 'content_main_text'})\n",
    "\n",
    "# text = article_body.get_text(strip=True)\n",
    "# keyword_counts = find_keywords_in_text(text)\n",
    "\n",
    "# # Выводим результат\n",
    "# print(f\"URL: {full_url}\")\n",
    "# print(\"Ключевые слова и количество упоминаний:\")\n",
    "# for keyword, count in keyword_counts.items():\n",
    "#     if count > 0:\n",
    "#         print(f\"{keyword}: {count}\")\n",
    "# print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
